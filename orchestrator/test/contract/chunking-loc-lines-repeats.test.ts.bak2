import { createDocumentProcessor } from '../../src/services/document.js';

const env = { OLLAMA_EMBED_MODEL: 'nomic-embed-text' } as any;
const fakeOllama = { embeddings: async (_m: string, _p: string) => Array.from({ length: 768 }, () => 0.5) } as any;

let capturedDocs: any[] = [];
const fakeDb = { upsertDocuments: async (docs: any[]) => { capturedDocs = docs; } } as any;

const docProc = createDocumentProcessor(env, { ollama: fakeOllama as any, db: fakeDb });

// Construire un texte plus long et très répétitif pour forcer >=3 chunks
const lineA = 'alpha alpha alpha alpha alpha';
const lineB = 'beta beta beta beta beta';
const blockA = Array.from({ length: 100 }, () => lineA).join('\n');
const blockB = Array.from({ length: 100 }, () => lineB).join('\n');
const text = `${blockA}\n${blockB}`;

const res = await docProc.processDocument({ notebookId: 'nb-rep', sourceId: 's-rep', text });
if (!res || typeof res.chunks !== 'number' || res.chunks < 3) {
  console.error('expected at least 3 chunks for repeated text, got', res?.chunks);
  process.exit(1);
}

// Vérifier monotonie minimale de loc.lines.to (non décroissant), et invariants de base
let lastTo = 0;
for (const d of capturedDocs) {
  const loc = d?.metadata?.loc?.lines;
  if (!loc || typeof loc.from !== 'number' || typeof loc.to !== 'number') {
    console.error('expected metadata.loc.lines with from/to');
    process.exit(1);
  }
  if (loc.from < 1 || loc.to < loc.from) {
    console.error('invalid loc.lines bounds', loc);
    process.exit(1);
  }
  if (loc.to < lastTo) {
    console.error('non-monotonic loc.lines.to', { lastTo, loc });
    process.exit(1);
  }
  lastTo = loc.to;
}

console.log('PASS chunking-loc-lines-repeats');
